{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook adapts some code from the TensorFlow tutorial: https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers  import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np  # Keras needs an older version on numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RProp import RProp\n",
    "from Wame import Wame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_lables(file):\n",
    "    data, lables = [], []\n",
    "    with open(file, \"r\") as f:\n",
    "        for row in f:\n",
    "            row = row.split()\n",
    "            row = [int(i) for i in row]\n",
    "            lables.append(row.pop(-1))\n",
    "            data.append(row)\n",
    "        return np.array(data), np.array(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_lables = extract_data_lables(\"data\\landsat\\sat.trn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_lables  = extract_data_lables(\"data\\landsat\\sat.tst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lables -= 1\n",
    "test_lables -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0:'red soil'\n",
    "    ,1:'cotton crop'\n",
    "    ,2:'grey soil'\n",
    "    ,3:'damp grey soil'\n",
    "    ,4:'soil with vegetation stubble'\n",
    "    ,5:'mixture class (all types present)'\n",
    "    ,6:'very damp grey soil'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels to 0-1\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Find a way to optimise these layers (will be needed for report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode lables\n",
    "Class lables need to be in an nxc array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "train_y = ohe.fit_transform(train_lables.reshape(-1, 1))\n",
    "test_y = ohe.transform(test_lables.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4435, 36)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4435, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for creating and testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_model(model, optimiser='adam'):\n",
    "    \"\"\"Trains a model using 25% validation, then tests the model with the best validation performance\"\"\"\n",
    "    \n",
    "    model.compile(optimizer=optimiser\n",
    "              ,loss='categorical_crossentropy'\n",
    "              ,metrics=['accuracy']\n",
    "             )\n",
    "    \n",
    "    history =  model.fit(\n",
    "        train_data\n",
    "        , train_y\n",
    "        , epochs=50\n",
    "        , validation_split=0.25\n",
    "        , verbose=0\n",
    "        ,callbacks = [\n",
    "            EarlyStopping(verbose=False, patience=20, monitor='val_loss'),\n",
    "            ModelCheckpoint('TestModel-progress', monitor='val_loss', verbose=False, save_best_only=True)],\n",
    "    )\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_data,  test_y, verbose = 0)\n",
    "    return (test_loss, test_acc)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_model(n_hidden=1, n_nodes=36):\n",
    "    model = Sequential()\n",
    "    # First hidden layer\n",
    "    model.add(Dense(n_nodes, input_dim=36))  # input_dim easier to use than input_shape\n",
    "    model.add(Activation('relu'))\n",
    "    # Additional hidden layers\n",
    "    for i in range(n_hidden-1):\n",
    "        model.add(Dense(n_nodes))\n",
    "        model.add(Activation('relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(6))  \n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_grid(n_hidden_lst, n_nodes_lst, optimiser):\n",
    "    test_losses = np.zeros((len(n_hidden_lst), len(n_nodes_lst)))\n",
    "    test_accs = np.zeros((len(n_hidden_lst), len(n_nodes_lst)))\n",
    "\n",
    "    for i, n_hidden in enumerate(n_hidden_lst):\n",
    "        for j, n_nodes in enumerate(n_nodes_lst):\n",
    "            model = create_seq_model(n_hidden, n_nodes)\n",
    "            test_result = train_test_model(model, optimiser)\n",
    "            test_losses[i, j] = test_result[0]\n",
    "            test_accs[i, j] = test_result[1]\n",
    "    \n",
    "    return test_accs, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial model check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806\n"
     ]
    }
   ],
   "source": [
    "model = create_seq_model(1, 36)\n",
    "\n",
    "#print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "\n",
    "model.compile(optimizer=Wame(clipnorm=1.0)\n",
    "              ,loss='categorical_crossentropy'\n",
    "              ,metrics=['accuracy']\n",
    "             )\n",
    "model.fit(\n",
    "        train_data\n",
    "        , train_y\n",
    "        , epochs=100\n",
    "        , validation_split=0.25\n",
    "        , verbose=0\n",
    " #       , callbacks = [print_weights]\n",
    "    )\n",
    "    \n",
    "test_loss, test_acc = model.evaluate(test_data,  test_y, verbose = 0)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.6206841e-04, 2.6822090e-07, 2.7121603e-02, 6.7287683e-04,\n",
       "        8.9406967e-08, 1.2874603e-05],\n",
       "       [1.6713142e-04, 6.8545341e-07, 7.8963637e-03, 1.0628700e-03,\n",
       "        3.8743019e-07, 9.5754862e-05],\n",
       "       [8.5324049e-05, 1.0430813e-06, 4.0685833e-03, 1.4330447e-03,\n",
       "        1.4603138e-06, 2.7629733e-04],\n",
       "       ...,\n",
       "       [6.7105889e-04, 2.9325485e-05, 1.2126565e-04, 1.6492605e-04,\n",
       "        7.3313713e-06, 2.2798777e-05],\n",
       "       [4.5374036e-04, 1.5437603e-05, 2.1111965e-04, 2.6634336e-04,\n",
       "        6.8843365e-06, 4.8696995e-05],\n",
       "       [3.9741397e-04, 1.1622906e-05, 2.5987625e-04, 3.2609701e-04,\n",
       "        6.8631471e-06, 7.0584261e-05]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test various 'adam' configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_lst = [1, 2, 3]\n",
    "n_nodes_lst = [10, 20, 30, 40]\n",
    "optimiser = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.797  0.8005 0.8085 0.811 ]\n",
      " [0.789  0.8065 0.8075 0.793 ]\n",
      " [0.8075 0.8135 0.805  0.779 ]]\n"
     ]
    }
   ],
   "source": [
    "test_accs_adam, test_losses_adam = train_test_grid(n_hidden_lst, n_nodes_lst, optimiser)\n",
    "print(test_accs_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test various 'wame' configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5915 0.6935 0.7965 0.777 ]\n",
      " [0.785  0.4075 0.8025 0.7965]\n",
      " [0.235  0.3315 0.2305 0.341 ]]\n"
     ]
    }
   ],
   "source": [
    "test_accs_wame, test_losses_wame = train_test_grid(n_hidden_lst, n_nodes_lst, Wame(clipnorm=1.0))\n",
    "print(test_accs_wame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_seq_model(n_hidden=2)\n",
    "# train_test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Val'], loc='upper left')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCW",
   "language": "python",
   "name": "mlcw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
