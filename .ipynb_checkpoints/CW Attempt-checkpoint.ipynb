{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers  import Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np  # Keras needs an older version of numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RProp import RProp\n",
    "from Wame import Wame\n",
    "from WameMosca import WameMosca\n",
    "from WameAdapted import WameAdapted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_lables(file):\n",
    "    data, lables = [], []\n",
    "    with open(file, \"r\") as f:\n",
    "        for row in f:\n",
    "            row = row.split()\n",
    "            row = [int(i) for i in row]\n",
    "            lables.append(row.pop(-1))\n",
    "            data.append(row)\n",
    "        return np.array(data), np.array(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_lables = extract_data_lables(\"data\\landsat\\sat.trn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_lables  = extract_data_lables(\"data\\landsat\\sat.tst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4435\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decriment to index from zero\n",
    "train_lables -= 1\n",
    "test_lables -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0:'red soil'\n",
    "    ,1:'cotton crop'\n",
    "    ,2:'grey soil'\n",
    "    ,3:'damp grey soil'\n",
    "    ,4:'soil with vegetation stubble'\n",
    "    ,5:'mixture class (all types present)'\n",
    "    ,6:'very damp grey soil'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1072,  479,  961,  415,  470,    0, 1038], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train_lables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels to 0-1\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Find a way to optimise these layers (will be needed for report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode lables\n",
    "Class lables need to be in an n x c array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "train_y = ohe.fit_transform(train_lables.reshape(-1, 1))\n",
    "test_y = ohe.transform(test_lables.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4435, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4435, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4435.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for creating and testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_model(n_hidden=1, n_neurons=36):\n",
    "    \"\"\"Create a sequential network with (1) hidden layers and (2) neurons in each layer.\n",
    "    Hidden layers are dense with relu activation\"\"\"\n",
    "    model = Sequential()\n",
    "    # First hidden layer\n",
    "    model.add(Dense(n_neurons, input_dim=36))  # input_dim easier to use than input_shape\n",
    "    model.add(Activation('relu'))\n",
    "    # Additional hidden layers\n",
    "    for i in range(n_hidden-1):\n",
    "        model.add(Dense(n_neurons))\n",
    "        model.add(Activation('relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(6))  \n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_model(model, optimiser):\n",
    "    \"\"\"Trains a model using 25% validation split each epoch, then tests the model with the best validation performance.\n",
    "    batch_size = 100, maximum epochs =100\"\"\"\n",
    "    \n",
    "    model.compile(optimizer=optimiser\n",
    "              ,loss='categorical_crossentropy'\n",
    "              ,metrics=['accuracy']\n",
    "             )\n",
    "    \n",
    "    start_t = time.time()\n",
    "    \n",
    "    history =  model.fit(\n",
    "        train_data\n",
    "        , train_y\n",
    "        , epochs=100\n",
    "        , validation_split=0.25\n",
    "        , verbose=0\n",
    "        , batch_size=32\n",
    "        , shuffle = True\n",
    "        ,callbacks = [\n",
    "            EarlyStopping(verbose=False, min_delta=0.0001, patience=15, monitor='val_acc', mode='max', restore_best_weights=True),\n",
    "        #    ModelCheckpoint('TestModel-progress'+str(counter), monitor='val_acc', verbose=False, save_best_only=True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    time_s = time.time() - start_t\n",
    "    \n",
    "    train_loss, train_acc = model.evaluate(train_data,  train_y, verbose = 0)\n",
    "    test_loss, test_acc = model.evaluate(test_data,  test_y, verbose = 0)\n",
    "    \n",
    "    epochs = history.history['val_acc']\n",
    "    best_epoch = epochs.index(max(epochs))\n",
    "    total_epochs = len(epochs)\n",
    "    sec_per_epoch = time_s / total_epochs\n",
    "    \n",
    "    return (train_acc, test_acc, train_loss, test_loss, best_epoch, sec_per_epoch, history)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_grid(n_hidden_lst, n_neurons_lst, optimiser, json_out, n_experiments=20):\n",
    "    \"\"\"Create, train and test multiple models using various structures. \n",
    "    Each structure is trialled via multiple experiments. Experiments uses a repeated sequence of random seeds.\n",
    "    Outputs: \n",
    "        - a (json-style) list of dictionaries of metrics from the experiments.\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if isinstance(optimiser, str):\n",
    "        opt_alias = optimiser\n",
    "    else:\n",
    "        opt_alias = type(optimiser).__name__\n",
    "        \n",
    "    print( len(n_hidden_lst)*len(n_neurons_lst), 'sets of', n_experiments, 'experiments to perform.')\n",
    "    \n",
    "    counter = 0\n",
    "    for i, n_hidden in enumerate(n_hidden_lst):\n",
    "        for j, n_neurons in enumerate(n_neurons_lst):\n",
    "            record_dict = OrderedDict({\n",
    "                'hidden_layers': n_hidden\n",
    "                ,'neurons': n_neurons\n",
    "                ,'optimiser': opt_alias\n",
    "                ,'n_experiments': n_experiments\n",
    "                ,'train_accuracies': []\n",
    "                ,'test_accuracies': []\n",
    "                ,'train_losses' : []\n",
    "                ,'test_losses' : []\n",
    "                ,'best_epochs': []\n",
    "                ,'seconds_per_epoch': []\n",
    "            })\n",
    "            \n",
    "            for k in range(n_experiments):\n",
    "                np.random.seed(10+k)\n",
    "                model = create_seq_model(n_hidden, n_neurons)\n",
    "                train_acc, test_acc, train_loss, test_loss, best_epoch, sec_per_epoch, _ = train_test_model(model, optimiser)\n",
    "                record_dict['train_accuracies'].append(train_acc)\n",
    "                record_dict['test_accuracies'].append(test_acc)\n",
    "                record_dict['train_losses'].append(train_loss)\n",
    "                record_dict['test_losses'].append(test_loss)\n",
    "                record_dict['best_epochs'].append(best_epoch)\n",
    "                record_dict['seconds_per_epoch'].append(sec_per_epoch)\n",
    "            \n",
    "            record_dict['avg_train_acc'] = sum(record_dict['train_accuracies'])/len(record_dict['train_accuracies'])\n",
    "            record_dict['avg_test_acc'] = sum(record_dict['test_accuracies'])/len(record_dict['test_accuracies'])\n",
    "            record_dict['avg_epoch'] = sum(record_dict['best_epochs'])/len(record_dict['best_epochs'])\n",
    "            record_dict['avg_sec_per_epoch'] = sum(record_dict['seconds_per_epoch'])/len(record_dict['seconds_per_epoch'])\n",
    "            record_dict['min_test_acc'] = min(record_dict['test_accuracies'])\n",
    "            record_dict['max_test_acc'] = max(record_dict['test_accuracies'])\n",
    "            record_dict['stdev_test_acc'] = np.std(record_dict['test_accuracies'])\n",
    "            record_dict['serr_test_acc'] = record_dict['stdev_test_acc'] / (record_dict['n_experiments']**0.5)\n",
    "            record_dict['CI_95'] = record_dict['serr_test_acc'] * 1.96\n",
    "            \n",
    "            results.append(record_dict)\n",
    "            counter += 1\n",
    "            with open(json_out, 'w') as f:\n",
    "                json.dump(results, f)\n",
    "            print(counter, 'sets done')\n",
    "    print('done!')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test various 'adam' configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_lst = [1, 2, 3]\n",
    "n_neurons_lst = [10, 20, 30, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run once:\n",
    "# Commented out after running \n",
    "# adam_results = train_test_grid(n_hidden_lst, n_neurons_lst, 'adam', 'results/adam_results.json', n_experiments=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test various WAME configurations using the altered update from Mosca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Josh\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "12 sets of 20 experiments to perform.\n",
      "WARNING:tensorflow:From C:\\Users\\Josh\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "1 sets done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1552667f0fa0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run once:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwameAdapted_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden_lst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neurons_lst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWameAdapted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'results/wameAdapted_results.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_experiments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-b07098d82551>\u001b[0m in \u001b[0;36mtrain_test_grid\u001b[1;34m(n_hidden_lst, n_neurons_lst, optimiser, json_out, n_experiments)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_seq_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msec_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_accuracies'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mrecord_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_accuracies'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-08d681dc3194>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[1;34m(model, optimiser)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         ,callbacks = [\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m#    ModelCheckpoint('TestModel-progress'+str(counter), monitor='val_acc', verbose=False, save_best_only=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         ]\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\MLCW\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run once:\n",
    "wameAdapted_results = train_test_grid(n_hidden_lst, n_neurons_lst, WameAdapted(), 'results/wameAdapted_results.json', n_experiments=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(40, input_dim=36))  # input_dim easier to use than input_shape\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(40))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(6))  \n",
    "# model.add(Activation('sigmoid'))\n",
    "    \n",
    "# model.compile(optimizer=WameAdapted()\n",
    "#               ,loss='categorical_crossentropy'\n",
    "#               ,metrics=['accuracy']\n",
    "#              )\n",
    "    \n",
    "# np.random.seed(123)\n",
    "\n",
    "# history =  model.fit(\n",
    "#     train_data\n",
    "#     , train_y\n",
    "#     , epochs=100\n",
    "#     , validation_split=0.25\n",
    "#     , verbose=0\n",
    "#     , batch_size=32\n",
    "#     , shuffle = True\n",
    "#     ,callbacks = [\n",
    "#         EarlyStopping(verbose=False, min_delta=0.0001, patience=15, monitor='val_acc', mode='max', restore_best_weights=True),\n",
    "#     #    ModelCheckpoint('TestModel-progress'+str(counter), monitor='val_acc', verbose=False, save_best_only=True)\n",
    "#     ]\n",
    "# )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for reporting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_test(results):\n",
    "    \"\"\"Helper function to retrieve the dictionary with the best average test accuracy from a results list\"\"\"\n",
    "    best_result = results[0]\n",
    "    best_test = results[0]['avg_test_acc']\n",
    "    for r in results:\n",
    "        if r['avg_test_acc'] > best_test:\n",
    "            best_test = r['avg_test_acc']\n",
    "            best_result = r\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_experiment(results, conditions):\n",
    "    \"\"\"results - dictionary output of train_test_grid()\n",
    "    conditions - a dictionary of keys and values that we want to match\n",
    "    will return the first experiment to match\"\"\"\n",
    "    for r in results:\n",
    "        matched = True\n",
    "        for k, v in conditions.items():\n",
    "            if r[k] != v:\n",
    "                matched = False\n",
    "                break\n",
    "        if matched:\n",
    "            return r\n",
    "\n",
    "def print_kpis(r):\n",
    "    print('test_acc', round(r['avg_test_acc']*100,1))\n",
    "    print('+- \\t', round(r['CI_95']*100,1))\n",
    "    print('stdev\\t', round(r['stdev_test_acc']*100,1))\n",
    "    print('epoch\\t', round(r['avg_epoch'],1))\n",
    "    print('time\\t', round(r['avg_sec_per_epoch'],2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = {'hidden_layers': 3\n",
    "              ,'neurons': 40}\n",
    "\n",
    "print_kpis(retrieve_experiment(adam_results, conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box and Whisker Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_results(results):\n",
    "    \"\"\"Helper function to create a tidy DataFrame from a results set. \n",
    "    Tidy dataframe is an easier format for data viz. and tabulation\n",
    "    The format of the DF is that there is a row per experiment (e.g. 20 experiments per arrangement)\"\"\"\n",
    "    \n",
    "    contents = []\n",
    "    for r in results:\n",
    "        col1 = r['optimiser']\n",
    "        col2 = r['hidden_layers']\n",
    "        col3 = r['neurons']\n",
    "        for e in range(r['n_experiments']):\n",
    "            col4 = r['train_accuracies'][e]\n",
    "            col5 = r['test_accuracies'][e]\n",
    "            contents.append([col1, col2, col3, col4, col5])\n",
    "    \n",
    "    df = pd.DataFrame(contents, columns=['optimiser','hidden_layers', 'neurons','train_accuracy', 'test_accuracy'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_from_results(adam_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='neurons',y='test_accuracy',data=df_test, hue='hidden_layers', whis=[0,100]).set_title('Adam Algorithm - Test Accuracies');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(x='hidden_layers',y='test_accuracy',data=df_test, hue='neurons');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Consider sub-plot to illustrate test accuracy vs train accuracy, or comparison of optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_experiment(wame_mosca_results, conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses_wame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = history.history['val_acc']\n",
    "epochs.index(max(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCW",
   "language": "python",
   "name": "mlcw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
